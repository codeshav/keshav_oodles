{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from oodles import Framework\n",
    "from oodles import Signal\n",
    "from oodles import monitor\n",
    "from oodles import ModelSignal, AnnotationMethod, Anomaly\n",
    "\n",
    "from dataset import input_to_dataset_transformation, read_json, write_json\n",
    "from model import run_real_world_inference, get_accuracy\n",
    "from pushup_signal import pushup_signal\n",
    "from train import train_model\n",
    "from contextlib import redirect_stdout\n",
    "orig_training_file = 'data/training_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = \"data\"\n",
    "# remote_url = \"https://oodles-dev-training-data.s3.amazonaws.com/data.zip\"\n",
    "# if not os.path.exists(data_dir):\n",
    "#     try:\n",
    "#         file_downloaded_ok = subprocess.check_output(\"wget \" + remote_url, shell=True)\n",
    "#     except:\n",
    "#         print(\"Could not load training data\")\n",
    "#     with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
    "#         zip_ref.extractall(\"./\")\n",
    "\n",
    "#     full_training_data = read_json(orig_training_file)\n",
    "#     np.random.seed(1)\n",
    "#     np.random.shuffle(full_training_data)\n",
    "#     reduced_training_data = full_training_data[0:1000]\n",
    "#     write_json(orig_training_file, reduced_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_test_cases = 'data/real_world_testing_data.json'\n",
    "data_save_fold_name = 'oodles_smart_data'\n",
    "golden_testing_file = 'data/golden_testing_data.json'\n",
    "annotation_args = {'master_file': 'data/master_annotation_data.json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  oodles_smart_data\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    # Define your signal to identify edge cases\n",
    "    \"checks\": [{\n",
    "        'type': Anomaly.EDGE_CASE, \n",
    "        \"signal_formulae\": (Signal(\"Pushup\", pushup_signal) | Signal(ModelSignal.BINARY_ENTROPY_CONFIDENCE, \n",
    "                is_model_signal=True, extra_args={'conf_threshold': 0.8}))}],\n",
    "\n",
    "    # Connect training pipeline to annotate data and retrain the model\n",
    "    \"training_args\": {\n",
    "        \"data_transformation_func\": input_to_dataset_transformation,  \n",
    "        \"annotation_method\": {\"method\": AnnotationMethod.MASTER_FILE, \"args\": annotation_args}, \n",
    "        \"training_func\": train_model, \n",
    "        \"fold_name\": data_save_fold_name,  \n",
    "        \"orig_training_file\": orig_training_file,  \n",
    "    },\n",
    "\n",
    "    # Connect evaluation pipeline to test retrained model against original model\n",
    "    \"evaluation_args\": {\n",
    "        \"inference_func\": get_accuracy,\n",
    "        \"golden_testing_dataset\": golden_testing_file,\n",
    "        \"metrics_to_check\": ['accuracy']\n",
    "    }\n",
    "}\n",
    "\n",
    "framework = Framework(cfg)\n",
    "\n",
    "@monitor(framework)\n",
    "def model_predict(args):\n",
    "    with open('evaluation_logs.txt', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            return args['model'].predict(args['kps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on:  data/training_data.json  which has  15788  data-points\n",
      "Training on:  data/training_data.json  which has  15788  data-points\n",
      "Model saved at:  trained_models/initial_model_\n"
     ]
    }
   ],
   "source": [
    "train_model('data/training_data.json', 'initial_model_',logistic_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_real_world_inference(real_world_test_cases, 'initial_model_', model_predict,logistic_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
